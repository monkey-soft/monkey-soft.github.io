{"pages":[{"title":"","text":"关于我这是猴哥的个人博客：『极客猴』。你还可以关注我的公众号：『极客猴』","link":"/README.html"}],"posts":[{"title":"深入理解HTTP","text":"HTTP是什么 HTTP全称是HyperText Transfer Protocal，即：超文本传输协议。它主要规定了客户端和服务器之间的通信格式。HTTP还是一个基于请求/响应模式的、无状态的协议；即我们通常所说的Request/Response。 HTTP与TCP的关系TCP协议是位于TCP/IP参考模型中的网络互连层，而HTTP协议属于应用层。因此，HTTP协议是基于TCP协议。 HTTP请求(HTTP Request)HTTP请求由三部分组成，分别是： 请求行 HTTP头 请求体 下面是请求示例： 123456789GET /?tn=90058352_hao_pg HTTP/1.1Host: www.hao123.comConnection: keep-aliveCache-Control: max-age=0Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8Upgrade-Insecure-Requests: 1User-Agent: Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 UBrowser/5.7.16400.16 Safari/537.36Accept-Encoding: gzip, deflateAccept-Language: zh-CN,zh;q=0.8 请求行同样也是由请求方法（POST/GET）方式、请求的主机、协议版本号三部分组成。下面为请求行的示例：GET /?tn=90058352_hao_pg HTTP/1.1 HTTP头HTTP头又细分为请求头(request header)、普通头(general header)、实体头(entity header)而HTTP头主要关注点是其字段 Accept作用: 浏览器可以接受的媒体类型例如： Accept: text/html 代表浏览器可以接受服务器回发的类型为 text/html 也就是我们常说的html文档通配符 * 代表任意类型例如： Accept: */* 代表浏览器可以处理所有类型,(一般浏览器发给服务器都是发这个) Accept-Language作用： 浏览器申明自己接收的语言。语言跟字符集的区别：中文是语言，中文有多种字符集，比如big5，gb2312，gbk等等；例如： Accept-Language: zh-CN,zh Accept-Encoding作用： 浏览器申明自己接收的编码方法，通常指定压缩方法（gzip，deflate）例如：Accept-Encoding: gzip, Accept-Encoding: deflate User-Agent作用： 告诉HTTP服务器， 客户端使用的操作系统的名称和版本以及浏览器的名称和版本.例如： User-Agent: Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 UBrowser/5.7.16400.16 Safari/537.36 Content-Type作用： 告诉服务器，请求的内容的类型常见的字段： 假设使用POST方式请求 text/xml [请求体为文本] application/json [请求体为JSON数据] application/xml [请求体为xml数据] image/jpeg [请求体为jpeg图片] multipart/form-data [请求体为表单] Cookie作用： 最重要的header，将cookie的值发送给HTTP服务器 Connection例如： Connection: keep-alive 当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的TCP连接不会关闭，如果客户端再次访问这个服务器上的网页，会继续使用这一条已经建立的连接例如： Connection: close 代表一个Request完成后，客户端和服务器之间用于传输HTTP数据的TCP连接会关闭， 当客户端再次发送Request，需要重新建立TCP连接。 Content-Length作用：发送给HTTP服务器数据的长度。例如： Content-Length: 18 Referer:作用： 提供了Request的上下文信息的服务器，告诉服务器我是从哪个链接过来的。 请求体这个只有post方式请求才有，get方式请求没有。 HTTP响应(HTTP Response)HTTP Response的结构跟Request的结构基本一样。同样分为三部分： 响应行 响应头 响应体 下面是响应示例： 1234567891011HTTP/1.1 200 OKCache-Control: max-age=0Content-Encoding: gzipContent-Length: 156474Content-Type: text/html;charset=UTF-8Cxy_all: 90058352_hao_pg+d4fa7f28cefb9b120f868558e440bafaDate: Sun, 20 Nov 2016 05:09:51 GMTExpires: Sun, 20 Nov 2016 05:09:51 GMTLfy: nj02.11Server: BWS/1.0Set-Cookie: __bsi=11619936655404239050_00_60_N_R_126_0303_c02f_Y; max-age=3600; domain=www.hao123.com; path=/ 响应行响应行由协议版本、响应状态构成下面为响应行的示例：HTTP/1.1 200 OK 响应头响应头关注点是字段，常见的字段如下： Cache-Control作用: 非常重要的规则。 这个用来指定Response-Request遵循的缓存机制。例如：Cache-Control:Public 可以被任何缓存所缓存Cache-Control:Private 内容只缓存到私有缓存中Cache-Control:no-cache 所有内容都不会被缓存 Content-Type作用：服务器告诉浏览器，自己响应的对象的类型和字符集例如:Content-Type: text/html; charset=utf-8Content-Type: image/jpeg Expires作用: 浏览器会在指定过期时间内使用本地缓存例如: Expires:Sun, 20 Nov 2016 05:09:51 GMT Connection跟HTTP头中的Connection是同样的原理 Content-Encoding跟HTTP中头的Content-Encoding是同样的原理 Content-Length作用：指明实体正文的长度，以字节方式存储的十进制数字来表示。例如: Content-Length: 156474 Date作用: 生成消息的具体时间和日期例如: Date: Sun, 20 Nov 2016 05:09:51 GMT 响应体响应体包含的内容是网页的内容信息，主要是html代码等","link":"/111.html"},{"title":"学爬虫之道","text":"近来在阅读 《轻量级 Django》,虽然还没有读完，但我已经收益颇多。我不得不称赞 Django 框架的开发人员，他们把 Web 开发降低门槛。Django 让我从对 Web 开发是一无所知到现在可以编写小型 web 应用，这很舒服。 Django 已经算是入门，所以自己把学习目标转到爬虫。自己接下来会利用三个月的时间来专攻 Python 爬虫。这几天，我使用“主题阅读方法”阅读 Python 爬虫入门的文档。制定 Python 爬虫的学习路线。 第一阶段：夯实入门要就是在打基础，所以要从最基础的库学起。下面是几个库是入门最经典的库 urllib它属于 Python 标准库。该库的作用是请求网页并下载数据。在学习该库之前，最好把 HTTP 协议了解下。这会大大提高后面的学习效率。 先学会如何使用 urllib 请求到数据，再学习一些高级用法。例如： 设置 Headers: 某些网站反感爬虫的到访，于是对爬虫一律拒绝请求。设置 Headers 可以把请求伪装成浏览器访问网站。 Proxy 的设置: 某些站点做了反倒链的设置，会将高频繁访问的 IP 地址封掉。所以我们需要用到代理池。 错误解析：根据 URLError 与 HTTPError 返回的错误码进行解析。 Cookie 的使用：可以模拟网站登录，需要结合 cookielib 一起使用。 rere 是正则表达式库。同时也是 Python 标准库之一。它的作用是匹配我们需要爬取的内容。所以我们需要掌握正则表达式常用符号以及常用方法的用法。 BeautifulSoupBeautifulSoup 是解析网页的一款神器。它可以从 HTML 或者 XML 文件中提取数据。配合 urllib 可以编写出各种小巧精干的爬虫脚本。 第二阶段：进阶当把基础打牢固之后，我们需要更进一步学习。使用更加完善的库来提高爬取效率 使用多线程使用多线程抓取数据，提高爬取数据效率。 学习 RequestsRequests 作为 urlilb 的替代品。它是更加人性化、更加成熟的第三方库。使用 Requests 来处理各种类型的请求，重复抓取问题、cookies 跟随问题、多线程多进程、多节点抓取、抓取调度、资源压缩等一系列问题。 学习 XpathXpath 也算是一款神器。它是一款高效的、表达清晰简单的分析语言。掌握它以后介意弃用正则表达式了。一般是使用浏览器的开发者工具 加 lxml 库。 学习 Selenium使用 Selenium，模拟浏览器提交类似用户的操作，处理js动态产生的网页。因为一些网站的数据是动态加载的。类似这样的网站，当你使用鼠标往下滚动时，会自动加载新的网站。 第三阶段：突破学习 ScrapyScrapy 是一个功能非常强大的分布式爬虫框架。我们学会它，就可以不用重复造轮子。 数据存储如果爬取的数据条数较多，我们可以考虑将其存储到数据库中。因此，我们需要学会 MySqlMongoDB、SqlLite的用法。更加深入的，可以学习数据库的查询优化。 第四阶段：为我所用当爬虫完成工作，我们已经拿到数据。我们可以利用这些数据做数据分析、数据可视化、做创业项目原始启动数据等。我们可以学习 NumPy、Pandas、 Matplotlib 这三个库。 NumPy ：它是高性能科学计算和数据分析的基础包。 Pandas : 基于 NumPy 的一种工具，该工具是为了解决数据分析任务而创建的。它可以算得上作弊工具。 Matplotlib：Python中最著名的绘图系统Python中最著名的绘图系统。它可以制作出散点图，折线图，条形图，直方图，饼状图，箱形图散点图，折线图，条形图，直方图，饼状图，箱形图等。","link":"/62.html"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/113.html"}],"tags":[{"name":"HTTP","slug":"HTTP","link":"/tags/HTTP/"},{"name":"Python","slug":"Python","link":"/tags/Python/"},{"name":"网络爬虫","slug":"网络爬虫","link":"/tags/%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB/"},{"name":"网络协议","slug":"网络协议","link":"/tags/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/"}],"categories":[{"name":"计算机网络","slug":"计算机网络","link":"/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"网络爬虫系列","slug":"网络爬虫系列","link":"/categories/%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E7%B3%BB%E5%88%97/"},{"name":"随笔","slug":"随笔","link":"/categories/%E9%9A%8F%E7%AC%94/"}]}